\chapter{ヒープ}
\chaplabel{heaps}
この章では優先度付きキューという役に立つデータ構造のふたつの実装を説明する。
いずれも特殊な二分木であり、\emph{ヒープ}（雑多に積まれた山）と呼ばれている。
\ejindex{heap}{ヒープ}%
\ejindex{binary heap}{にぶんひーぷ@二分ヒープ}%
\ejindex{heap!binary}{ヒープ!にぶん@二分}%
これは二分探索木が高度に構造化されながら積み上げられていたのとは対照的である。

ひとつめのヒープの実装は配列を使って完全二分木をシミュレートする。
この効率的な実装はヒープソート（\secref{heapsort}参照）という名の、最速の整列アルゴリズムのうちのひとつを実装するのに使える。
ふたつめに紹介する実装は、より柔軟な二分木である。
この実装では、ある優先度付きキューの要素を、別の優先度付きキューに取り込む#meld(h)#操作を行うことができる。

\section{#BinaryHeap#：暗黙の二分木}
\seclabel{binaryheap}

\index{BinaryHeap@#BinaryHeap#}%
（優先度付き）キューの最初の実装は400年以上前に発見された手法に基づく。
\emph{Eytzinger法}
\ejindex{Eytzinger's method}{Eytzingerの方法}%
では木のノードを幅優先順に配列に入れて完全二分木を表現する。
（\secref{bintree:traversal}を参照せよ。）
こうすると、根は0番目、根の左の子は1番目、右の子は2番目、根の左の子の左の子は3番目の位置に格納される。
\figref{eytzinger}を参照せよ。

\begin{figure}
  \begin{center}
    \includegraphics[scale=0.90909]{figs/eytzinger}
  \end{center}
  \caption{Eytzinger法により、配列を使って完全二分木を表現する。}
  \figlabel{eytzinger}
\end{figure}

Eytzinger法を大きな木に適用してみると、規則性が見えてくる。
添え字#i#のノードの左の子の添え字は$#left(i)#=2#i#+1$であり、右の子の添え字は$#right(i)#=2#i#+2$である。
また、添え字#i#のノードの親の添え字は$#parent(i)#=(#i#-1)/2$である。
\codeimport{ods/BinaryHeap.left(i).right(i).parent(i)}

#BinaryHeap#はこの手法を使って完全二分木を暗黙に表現する。
特に、この木の中では要素は\emph{ヒープ順}に並んでいる。
\ejindex{heap-ordered binary tree}{ひーぷじゅんにぶんぎ@ヒープ順二分木}%
\ejindex{binary tree!heap-ordered}{にぶんぎ@二分木!ひーぷじゅん@ヒープ順}%
\ejindex{heap order}{ひーぷじゅん@ヒープ順}%
すなわち、添え字#i#の位置に格納されている値は、#parent(i)#に格納されている値以上である。（ただし、$#i#=0$である根は除く。）
このとき、優先度付き#Queue#における最小値が0番目の位置（根）に格納されていることがわかる。

#BinaryHeap#では#n#個の要素が配列#a#に格納されている。
\codeimport{ods/BinaryHeap.a.n}

#add(x)#の実装は簡単である。
他の配列ベースのデータ構造と同じく、まずは#a#が一杯かどうかを確認する。
（$#a.length#=#n#$かどうかを確認する。）
もしそうなら#a#を拡張する。
続いて#x#を#a[n]#に入れ、#n#を1増やす。
あとはヒープ性を保てばよい。
これは#x#とその親とを交換する操作を、#x#が親以上になるまで繰り返せばよい。
\figref{heap-insert}を参照せよ。
\codeimport{ods/BinaryHeap.add(x).bubbleUp(i)}

\begin{figure}
  \begin{center}
    \includegraphics[height=\QuarterHeightScaleIfNeeded]{figs/heap-insert-1} \\
    \includegraphics[height=\QuarterHeightScaleIfNeeded]{figs/heap-insert-2} \\
    \includegraphics[height=\QuarterHeightScaleIfNeeded]{figs/heap-insert-3} \\
    \includegraphics[height=\QuarterHeightScaleIfNeeded]{figs/heap-insert-4} \\
  \end{center}
  \caption{#BinaryHeap#に値6を追加する。}
  \figlabel{heap-insert}
\end{figure}

#remove()#はヒープから最小の値を削除するが、この実装にはすこし工夫が必要だ。
根が最小値なのはわかっているが、これを削除したあとにもヒープ性が成り立つことを保証しなければならない。

もっとも簡単な方法は根と#a[n-1]#を交換し、交換後に#a[n-1]#にある値を削除し、#n#を1小さくすることだ。
しかし、その結果新たな根はおそらく最小値ではなくなっている。
そのためこれを下方向に動かす必要がある。
このため、この要素を子供と比較することを繰り返す。
もしこの要素が三つ（自分と子供達）のうち最小ならば処理を終了する。
そうでないなら、子供達のうち小さいものと、この要素とを入れ替え、処理を繰り返す。
\codeimport{ods/BinaryHeap.remove().trickleDown(i)}

\begin{figure}
  \begin{center}
    \includegraphics[height=\QuarterHeightScaleIfNeeded]{figs/heap-remove-1} \\
    \includegraphics[height=\QuarterHeightScaleIfNeeded]{figs/heap-remove-2} \\
    \includegraphics[height=\QuarterHeightScaleIfNeeded]{figs/heap-remove-3} \\
    \includegraphics[height=\QuarterHeightScaleIfNeeded]{figs/heap-remove-4} \\
  \end{center}
  \caption{#BinaryHeap#から最小の値4を削除する。}
  \figlabel{heap-remove}
\end{figure}

他の配列ベースのデータ構造と同様に、#resize()#のための時間を無視する。
この実行時間は\lemref{arraystack-amortized}の償却解析によってわかる。
すると、#add(x)#・#remove()#の実行時間は（暗黙の）二分木の高さに依存する。
嬉しいことに、これは\emph{完全}二分木である。
\ejindex{binary tree!complete}{にぶんぎ@二分木!かんぜん@完全}%
\ejindex{complete binary tree}{かんぜんにぶんぎ@完全二分木}%
最大の深さを除く各深さには、可能な最大数のノードがある。
よって、$h$を木の高さとすると、少なくとも$2^h$個のノードがある。
言い換えると、次の式が成り立つ。
\[
  #n# \ge 2^h
\]
両辺の対数を取ると、次の式が成り立つ。
\[
   h \le \log #n#
\]
以上より、#add(x)#・#remove()#のいずれの実行時間も$O(\log #n#)$である。

\subsection{要約}

次の定理は#BinaryHeap#の性能をまとめたものだ。

\begin{thm}\thmlabel{binaryheap}
  #BinaryHeap#は（優先度付き）#Queue#インターフェースの実装である。
  #BinaryHeap#は#add(x)#・#remove()#をサポートし、#resize()#のコストを無視すると、いずれの実行時間も$O(\log #n#)$である。

  空の#BinaryHeap#から任意の$m$個の#add(x)#・#remove()#からなる操作の列を実行する。このときすべての#resize()#にかかる時間の合計は$O(m)$である。
\end{thm}

\section{#MeldableHeap#：ランダムなMeldableヒープ}
\seclabel{meldableheap}
XXX: melbadleは定訳がある?

\index{MeldableHeap@#MeldableHeap#}%
この節では、#MeldableHeap#を紹介する。
これは優先度付き#Queue#の実装で、背後にある構造もまたヒープであるものである。
しかし、#BinaryHeap#のようには要素数から二分木の形が一意には決まらず、#MeldableHeap#における背後にある二分木の形状には制約がない。

#MeldableHeap#における#add(x)#・#remove()#は#merge(h1,h2)#を使って実装される。
この操作はヒープのノード#h1#と#h2#を引数にとり、それぞれを根とするふたつの部分木内のすべてのノードを含むヒープの根を返す。

嬉しいことに#merge(h1,h2)#は再帰的に定義できる。
\figref{meldable-merge}を参照せよ。
#h1#または#h2#が#nil#なら、単に#h2#, #h1#をそれぞれ返せばよい。
そうでないとき、$#h1.x# \le #h2.x#$として一般性を失わない。
このとき新たなヒープの根は#h1.x#を含む。
#h2#は再帰的に#h1.left#か#h1.right#の望む方と併合してよい。
ここでランダム性の出番だ。
コインを投げ、#h#を#h1.left#と#h1.right#のどちらと併合するかを決める。
\codeimport{ods/MeldableHeap.merge(h1,h2)}

\begin{figure}
  \centering{\includegraphics[width=\ScaleIfNeeded]{figs/meldable-merge}}
  \caption{#h1#と#h2#を併合するために、#h1.left#または#h1.right#のいずれかに#h2#を併合する。}
  \figlabel{meldable-merge}
\end{figure}

次の節では#merge(h1,h2)#の実行時間の期待値が$O(\log #n#)$であることを示す。
ここで、#n#は#h1#と#h2#の要素数の合計である。

#merge(h1,h2)#を使えば、#add(x)#は簡単である。
#x#を含む新たなノード#u#を作り、#u#をヒープの根と併合すればよい。
\codeimport{ods/MeldableHeap.add(x)}
このとき実行時間の期待値は$O(\log (#n#+1)) = O(\log #n#)$である。

#remove()#も同様に簡単である。
削除したいのは根なので、そのふたつの子を併合し、その結果を新たな根とすればよい。
\codeimport{ods/MeldableHeap.remove()}
このときも実行時間の期待値は$O(\log #n#)$である。

さらに#MeldableHeap#は他の色々な操作も$O(\log #n#)$の期待実行時間で実装できる。
例えば次のものがある。
\begin{itemize}
\item #remove(u)#：ヒープからノード#u#を削除する
\item #absorb(h)#：このヒープに#h#の要素をすべて追加し、#h#を空にする
\end{itemize}
いずれの操作も定数回だけの#merge(h1,h2)#を使って実装できる。

\subsection{#merge(h1,h2)#の解析}

#merge(h1,h2)#の解析は二分木のランダムウォークに基づく。
二分木の\emph{ランダムウォーク}は根から始まる。
各ステップではコインを投げ、その結果に応じて今のノードの右か左の子に進む。
木からはみ出ると処理を終了する。（これは今のノードが#nil#になったときである。）

次の補題は注目に値する。
これは二分木の形状に関わらず成り立つためである。

\begin{lem}\lemlabel{tree-random-walk}
#n#個のノードからなる二分木におけるランダムウォークの長さの期待値は#\log (n+1)#以下である。
\end{lem}

\begin{proof}
#n#に関する帰納法により証明する。
$#n#=0$のとき、ステップ数は$0=\log (#n#+1)$である。
以下では、任意の非負整数$#n#'< #n#$について、示したい補題が成り立つと仮定する。

$#n#_1$を根の左の部分木の大きさとし、$#n#_2=#n#-#n#_1-1$を根の右の部分木の大きさとする。
根からはじめて、一歩進み、大きさ$#n#_1$または$#n#_2$の部分木について処理を続ける。
仮定より、ステップ数の期待値は次のようになる。
\[
    \E[W] = 1 + \frac{1}{2}\log (#n#_1+1) + \frac{1}{2}\log (#n#_2+1)
\]
これは$#n#_1$と$#n#_2$はいずれも$#n#$より小さいためである。
$\log$は凹関数なので、$\E[W]$は$#n#_1=#n#_2=(#n#-1)/2$で最大値を取る。
%To maximize this,
%over all choices of $#n#_1\in[0,#n#-1]$, we take the derivative and obtain
%\[
%    (\E[W])' = \frac{1}{2}(c/#n#_1 - c/(#n#-#n#_1-1)) \enspace , 
%\]
%which is equal to 0 when $#n#_1 = (#n#-1)/2$.  We can establish that
%this is a maximum fairly easily, so
よって、ランダムウォークのステップ数の期待値は次のようになる。
\begin{align*}
    \E[W]
    & = 1 + \frac{1}{2}\log (#n#_1+1) + \frac{1}{2}\log (#n#_2+1) \\
   & \le  1 + \log ((#n#-1)/2+1) \\
   & =  1 + \log ((#n#+1)/2) \\
   & =  \log (#n#+1)  \enspace \qedhere
\end{align*}
\end{proof}

余談だが、情報理論について知っている読者は\lemref{tree-random-walk}の証明をエントロピーの用語で言い換えることができるだろう。
\begin{proof}[\lemref{tree-random-walk}の情報理論的な証明]
$d_i$を$i$番目の外部ノード(#nil#)の深さとする。
#n#個のノードを持つ二分木は#n+1#個の外部ノードを持つことを思い出すこと。
ランダムウォークが$i$番目の外部ノードにたどり着く確率は$p_i=1/2^{d_i}$である。
よってランダムウォークのステップ数の期待値は次のように計算できる。
\[
   H=\sum_{i=0}^{#n#} p_id_i
    =\sum_{i=0}^{#n#} p_i\log\left(2^{d_i}\right)
    = \sum_{i=0}^{#n#}p_i\log({1/p_i})
\]
右辺は$#n#+1$個の要素に渡って確率分布のエントロピーを求めたものだとわかるだろう。
$#n#+1$個の要素にわたる分布のエントロピーに関する基本的な事実として、これはこの値は$\log(#n#+1)$を超えない。
よって補題が示された。
\end{proof}

ランダムウォークに関するこの結果より、#merge(h1,h2)#の実行時間の期待値は$O(\log #n#)$であることを示せる。

\begin{lem}
  #h1#・#h2#はふたつのヒープの根であり、それぞれのヒープは$#n#_1$, $#n#_2$個のノードを含むとする。
  このとき、#merge(h1,h2)#の実行時間は$O(\log #n#)$以下である。
  ただし、ここで$#n#=#n#_1+#n#_2$である。
\end{lem}

\begin{proof}
併合の各ステップはランダムウォークを1ステップで、#h1#か#h2#のいずれかを根とする部分木に進む。
このアルゴリズムはふたつのランダムウォークのどちらかが木からはみ出すと終了する。
（これは$#h1#=#null#$または$#h2#=#null#$のときである。）
よって、併合アルゴリズムのステップ数の期待値は次の値以下である。
  \[
     \log (#n#_1+1) + \log (#n#_2+1) \le 2\log #n# \qedhere
  \]
\end{proof}

\subsection{要約}

次の定理は#MeldableHeap#をまとめるものである。

\begin{thm}\thmlabel{meldableheap}
  #MeldableHeap#は優先度付き#Queue#インターフェースを実装する。
  #add(x)#・#remove()#をサポートし、いずれの実行時間の期待値も$O(\log #n#)$である。
\end{thm}

\section{ディスカッションと練習問題}

完全二分木を配列またはリストを使って暗黙に表現する方法はEytzinger \cite{e1590}が最初に提案したようである。
彼は高貴な一族の家系図が書いてある本でこれを使った。
\ejindex{pedigree family tree}{かけいず@家系図}%
この章で説明した#BinaryHeap#はWilliams \cite{w64}が最初に提案したものである。

この章で説明したランダム操作を利用した#MeldableHeap#はGambinとMalinowski \cite{gm98}が最初に提案した。
他のMeldable Heapも存在し、
leftist heaps \cite[Section~5.3.2]{c72,k97v3}、
\ejindex{leftist heap}{leftist heap}%
\ejindex{heap!leftist}{ヒープ!leftist}%
binomial heaps \cite{v78}、
\ejindex{binomial heap}{にこうひーぷ@二項ヒープ}%
\ejindex{heap!binomial}{ヒープ!にこう@二項}%
Fibonacci heaps \cite{ft87}、
\ejindex{Fibonacci heap}{フィボナッチヒープ}%
\ejindex{heap!Fibonacci}{ヒープ!フィボナッチ}%
pairing heaps \cite{fsst86}、
\ejindex{pairing heap}{pairing heap}%
\ejindex{heap!pairing}{ヒープ!pairing}%
skew heaps \cite{st83}などがある。
\ejindex{skew heap}{skew heap}%
\ejindex{heap!skew}{ヒープ!skew}%
しかし、いずれも#MeldableHeap#ほどシンプルではない。

上のデータ構造の中には#decreaseKey(u,y)#をサポートするものもある。
\index{decreaseKey@#decreaseKey(u,y)#}%
これはノード#u#に格納される値を小さくして#y#とするものである。
（これを実行する前には$#y#\le#u.x#$である必要がある。）
上に挙げたデータ構造の大部分では、ノード#u#を削除し、#y#を追加するので$O(\log #n#)$の時間がかかる。
しかし、一部のデータ構造ではこれをもっと効率的に実装できる。
とくに、Fibonacci heapsでは$O(1)$の償却実行時間で、pairing heaps \cite{e09}の特殊なものでは$O(\log\log #n#)$の償却実行時間でそれぞれ#decreaseKey(u,y)#を実行できる。
効率的な#decreaseKey(u,y)#はグラフアルゴリズムの高速化に役立つ。（例えばダイクストラ法）
\cite{ft87}

\begin{exc}
  \figref{heap-insert}に示した#BinaryHeap#に7, 3を順に追加する様子を図示せよ。
\end{exc}

\begin{exc}
\figref{heap-remove}に示した#BinaryHeap#から次のふたつの値（6と8）を順に削除する様子を図示せよ。
\end{exc}

\begin{exc}
  #remove(i)#を実装せよ。
  これは#BinaryHeap#における#a[i]#の値を削除するメソッドである。
  このメソッドの実行時間は$O(\log #n#)$でなければならない。
  また、なぜこのメソッドが役立ちそうにないかを説明せよ。
\end{exc}

\begin{exc}\exclabel{general-eytzinger}
  \ejindex{tree!$d$-ary}{木!$d$-aray}%
  $d$分木は二分木の一般化である。
  これは各内部ノードが$d$個の子を持つ木である。
  Eytzingerの方法を使えば、完全$d$分木も配列を使って表現できる。
  すなわち、添え字#i#が与えられたとき、#i#の親と、#i#の$d$個の子、それぞれの添え字を計算する方法を与えよ。
\end{exc}

\begin{exc}
  \index{DaryHeap@#DaryHeap#}%
  \excref{general-eytzinger}で学んだことを使って\emph{#DaryHeap#}を設計・実装せよ。
  これは$d$分木版の#BinaryHeap#である。
  #DaryHeap#の操作の実行時間を解析し、#DaryHeap#の性能を#BinaryHeap#と比較せよ。
\end{exc}

\begin{exc}
  \figref{meldable-merge}に示した#MeldableHeap#に17, 82を順に追加する様子を図示せよ。
  ランダムなビットが必要なときにはコインを使うこと。
\end{exc}

\begin{exc}
  \figref{meldable-merge}に示した#MeldableHeap#から、次のふたつの値（4と8）を削除せよ。
  ランダムなビットが必要なときにはコインを使うこと。
\end{exc}

\begin{exc}
#MeldableHeap#からノード#u#を削除する#remove(u)#を実装せよ。
ただし、このメソッドの実行時間の期待値は$O(\log #n#)$でなければならない。
\end{exc}

\begin{exc}
#BinaryHeap#・#MeldableHeap#における二番目に小さい値を定数時間で見つける方法を示せ。
\end{exc}

\begin{exc}
#BinaryHeap#・#MeldableHeap#におけるk番目に小さい値を$O(k\log k)$の時間で見つける方法を示せ。
（ヒント：別のヒープを使うといいかもしれない。）
\end{exc}

\begin{exc}
#k#個の整列済みリストであって、合計の長さが#n#であるものがあるとき、ヒープを使ってこれらのリストを一つの整列済みリストにする方法を示せ。
このとき実行時間は$O(n\log k)$でなければならない。
（ヒント：$k=2$の場合から考えてみるのがよいかもしれない。）
\end{exc}
