\chapter{ランダム二分探索木}
\chaplabel{rbs}

この章では、ランダム化を利用し、各操作を$O(\log #n#)$の期待実行時間で実行できる二分探索木を紹介する。

\section{ランダム二分探索木}
\seclabel{rbst}

\figref{rbs-lvc}のふたつの二分探索木を見てほしい。
これらはいずれも$#n#=15$個のノードからなる。
左のものはリストであり、右のものは完全にバランスされた二分探索木である。
左の木の高さは$#n#-1=14$で、右の木の高さは3である。

\begin{figure}
  \begin{center}
    \begin{tabular}{cc}
      \includegraphics[scale=0.90909,scale=0.95]{figs/bst-path} &
      \includegraphics[scale=0.90909,scale=0.95]{figs/bst-balanced}
    \end{tabular}
  \end{center}
  \caption{整数$0,\ldots,14$を含むふたつの二分探索木}
  \figlabel{rbs-lvc}
\end{figure}

このふたつの木をどうすれば構築できるかを考えてみよう。
左の木は空の#BinarySearchTree#に次の要素を順に追加すると得られる。
\[
    \langle 0,1,2,3,4,5,6,7,8,9,10,11,12,13,14 \rangle
\]
この木が得られる追加操作の列はこの列に限る。（証明は#n#についての帰納法で行う。）
一方、右の木は次の要素を順に追加すると得られる。
\[
    \langle 7,3,11,1,5,9,13,0,2,4,6,8,10,12,14 \rangle
\]
他にも
\[
    \langle 7,3,1,5,0,2,4,6,11,9,13,8,10,12,14 \rangle
\]
や
\[
    \langle 7,3,1,11,5,0,2,4,6,9,13,8,10,12,14 \rangle
\]
からも、この木が得られる。
右の木が得られる追加操作の列は$21,964,800$種類ある。
一方で、左の木が得られる追加操作の列は上のものだけである。

上の例から、定性的には、$0,\ldots,14$をランダムに並び替え、その要素を順に二分探索木に入れていくと、（\figref{rbs-lvc}の右のもののような）とてもバランスの良い木ができることが多く、（\figref{rbs-lvc}の左のもののような）非常にバランスの悪い木ができることは滅多にないとわかる。

このことを形式的に述べるために、ランダム二分探索木を考える。
次の手順で大きさ#n#の\emph{ランダム二分探索木}が得られる。
\index{random binary search tree}%
\index{binary search tree!random}%

$0,\ldots,#n#-1$のランダムな置換をひとつ選ぶ。
これを$#x#_0,\ldots,#x#_{#n#-1}$とし、順に#BinarySearchTree#に追加する。
ここで、\emph{ランダムな置換}
\index{permutation!random}%
\index{random permutation}%
とは、$#n#!$個ある$0,\ldots,#n#-1$の並び替えから、いずれも等しい確率$1/#n#!$でひとつ選出したものをいう。

値$0,\ldots,#n#-1$を、順序の定義された集合の要素#n#個組みと置き換えても、ランダム二分探索木の性質には影響しないことに注意する。
$#x#\in\{0,\ldots,#n#-1\}$は、単にサイズ#n#の順序付き集合における#x#番目の要素を表しているのである。

ランダム二分探索木の主要な性質を説明する前に、少し脱線してランダムな構造を考えるときによく出てくる数の話をしよう。
非負整数を$k$とするとき、$k$番目の\emph{調和数}$H_k$は次のように定義される。
\index{harmonic number}%
\index{H@$H_k$ (harmonic number)}%
\[
  H_k = 1 + 1/2 + 1/3 + \cdots + 1/k
\]
調和数$H_k$は単純な閉じた式では書けないが、自然対数と密接な関係を持つ。
具体的には、次の式が成り立つ。
\[
  \ln k < H_k \le \ln k + 1
\]
\newcommand{\hint}{\int_1^k\! (1/x)\, \mathrm{d}x}%
解析学を学んでいれば、$\hint = \ln k$からこれを導けるだろう。
積分は曲線と$x$軸との囲む領域の面積として解釈できるので、$H_k$の値の下界は$\hint$、上界は$1+ \hint$である。
（\figref{harmonic-integral}を見ると視覚的に理解できるだろう。）

\begin{figure}
  \begin{center}
    \begin{tabular}{cc}
      \includegraphics[width=\HalfScaleIfNeeded]{figs/harmonic-2}
        & \includegraphics[width=\HalfScaleIfNeeded]{figs/harmonic-3}
    \end{tabular}
  \end{center}
  \caption{$k$番目の調和数$H_k=\sum_{i=1}^k 1/i$の上界・下界を積分値として与える。各積分値は図の斜線部の面積であり、$H_k$は長方形の部分の面積である。}
  \figlabel{harmonic-integral}
\end{figure}

\begin{lem}\lemlabel{rbs}
大きさ#n#のランダム二分探索木について、次の補題が成り立つ。
  \begin{enumerate}
    \item 任意の$#x#\in\{0,\ldots,#n#-1\}$について、#x#の探索経路の長さの期待値は$H_{#x#+1} + H_{#n#-#x#} - O(1)$である。\footnote{$#x#+1$と$#n#-#x#$はそれぞれ木の要素のうち#x#以上のものの個数、#x#以下のものの個数と解釈できる。}
    \item 任意の$#x#\in(-1,n)\setminus\{0,\ldots,#n#-1\}$について、#x#の探索経路の長さの期待値は$H_{\lceil#x#\rceil} + H_{#n#-\lceil#x#\rceil}$である。
  \end{enumerate}
\end{lem}

\lemref{rbs}は次の小節で証明する。
ここでは\lemref{rbs}のふたつの項目の意味を考える。
ひとつめは、サイズ#n#の木から要素を探索するとき、探索経路の長さの期待値は$2\ln n + O(1)$以下であると主張する。
ふたつめは、木に含まれない要素を探す場合についても、同じことを主張する。
これらを比べると、木に含まれない要素を探すより、含まれる要素を探す方が、少しだけ早いことがわかる。


\subsection{\lemref{rbs}の証明}

\lemref{rbs}を証明するための鍵となる考察は次のものだ。
ランダム二分探索木$T$における値$#x# \in (-1,#n#)$の探索経路に$i < #x#$を満たす#i#をキーとするノードが含まれる必要十分条件は、$T$を作るランダムな置換において$i$が$\{i+1,i+2,\ldots,\lfloor#x#\rfloor\}$のいずれよりも前に現れることである。

\figref{rbst-records}でいうと、$\{i,i+1,\ldots,\lfloor#x#\rfloor\}$のいずれかが追加されるまで、探索経路$(i-1,\lfloor#x#\rfloor+1)$に含まれる要素の探索経路は等しいことから確認できる。
（あるふたつの要素の探索経路が異なるならば、ふたつの要素の一方よりは大きく、他方よりは小さいある要素が存在するのである。）
$j$をランダムな置換において最初に現れる$\{i,i+1,\ldots,\lfloor#x#\rfloor\}$の要素とする。
$j$はずっと#x#の探索経路上にあることに注意する。
$j\neq i$ならば$j$を含むノード$#u#_j$は$i$を含むノード$#u#_i$より先に作られる。
そしてその後、$i$が追加されるとき、$i<j$なので$#u#_j#.left#$を根とする部分木に$#u#_i$は追加される。
一方#x#の探索経路はこの部分木を通らない。
なぜならこの経路は$#u#_j$を訪問したあと$#u#_j#.right#$に向かうからである。

\begin{figure}
  \begin{center}
    \includegraphics[width=\ScaleIfNeeded]{figs/rbst-records}
  \end{center}
  \caption{The value $i<#x#$ is on the search path for #x# if and only
   if $i$ is the first element among $\{i,i+1,\ldots,\lfloor#x#\rfloor\}$ added to the tree.}
  \figlabel{rbst-records}
\end{figure}

$i>#x#$の場合も、キー$i$が#x#の探索経路に含まれる必要十分条件は、$T$を作るランダムな置換において、$i$が$\{\lceil#x#\rceil, \lceil#x#\rceil+1,\ldots,i-1\}$のいずれよりも前に現れることである。

$\{0,\ldots,#n#\}$のランダムな置換を考えるとき、そのうち$\{i,i+1,\ldots,\lfloor#x#\rfloor\}$または$\{\lceil#x#\rceil, \lceil#x#\rceil+1,\ldots,i-1\}$だけを取り出した部分列も、やはりそれぞれのランダムな置換になっている。
ランダムな置換を作ると、どの要素もみな等しい確率で先頭に来るので次の式が得られる。
\[
  \Pr\{\mbox{$i$が#x#の探索経路に含まれる}\}
  = \left\{ \begin{array}{ll}
     1/(\lfloor#x#\rfloor-i+1) & \mbox{if $i < #x#$} \\
     1/(i-\lceil#x#\rceil+1) & \mbox{if $i > #x#$}
     \end{array}\right
\]

この考察により、調和数の簡単な計算で\lemref{rbs}を証明できる。

\begin{proof}[Proof of \lemref{rbs}]
$I_i$を指示確率変数とする。
この値は、$i$が探索経路に現れるときは1、そうでないときは0である。
このとき探索経路の長さを次のように計算できる。
\[
  \sum_{i\in\{0,\ldots,#n#-1\}\setminus\{#x#\}} I_i
\]
よって$#x#\in\{0,\ldots,#n#-1\}$なら探索経路の長さの期待値は次のように計算できる。（\figref{rbst-probs}.aを見よ。）
\begin{align*}
  \E\left[\sum_{i=0}^{#x#-1} I_i + \sum_{i=#x#+1}^{#n#-1} I_i\right]
   & =  \sum_{i=0}^{#x#-1} \E\left[I_i\right]
         + \sum_{i=#x#+1}^{#n#-1} \E\left[I_i\right] \\
   & = \sum_{i=0}^{#x#-1} 1/(\lfloor#x#\rfloor-i+1)
         + \sum_{i=#x#+1}^{#n#-1} 1/(i-\lceil#x#\rceil+1) \\
   & = \sum_{i=0}^{#x#-1} 1/(#x#-i+1)
         + \sum_{i=#x#+1}^{#n#-1} 1/(i-#x#+1) \\
   & = \frac{1}{2}+\frac{1}{3}+\cdots+\frac{1}{#x#+1} \\
   & \quad {} + \frac{1}{2}+\frac{1}{3}+\cdots+\frac{1}{#n#-#x#} \\
   & = H_{#x#+1} + H_{#n#-#x#} - 2  \enspace .
\end{align*}
値$#x#\in(-1,n)\setminus\{0,\ldots,#n#-1\}$の場合も同様である。（\figref{rbst-probs}.bを見よ。）
\end{proof}

\begin{figure}
  \begin{center}
    \begin{tabular}{@{}c@{}}
      \includegraphics[width=\ScaleIfNeeded]{figs/rbst-probs-a} \\ (a) \\[2ex]
      \includegraphics[width=\ScaleIfNeeded]{figs/rbst-probs-b} \\ (b) \\[2ex]
    \end{tabular}
  \end{center}
  \caption{#x#の探索経路に各要素が現れる確率~(a)~#x#が整数のとき~(b)~#x#が整数でないとき}
  \figlabel{rbst-probs}
\end{figure}

\subsection{要約}

次の定理はランダム二分探索木の性能をまとめたものだ。

\begin{thm}\thmlabel{rbs}
ランダム二分探索木は$O(#n#\log #n#)$の時間で構築できる。
ランダム二分探索木における#find(x)#の期待実行時間は$O(\log #n#)$である。
\end{thm}

\thmref{rbs}における期待値は、ランダム二分探索木を作るための置換のランダム性に基づく。つまり、#x#をランダムに選ぶことには依存しておらず、任意の#x#についてこれは成り立つ。

% XXX: Randomized Binary Search Tree は random binary search treeをどう訳し分けるか
%\section{#Treap#: A Randomized Binary Search Tree}
\section{#Treap#}
\seclabel{treap}

\index{Treap@#Treap#}%
ランダム二分探索木の問題は当然ながら動的でないことだ。
#SSet#インターフェースを実装するために必要な#add(x)#・#remove(x)#をサポートしていないのである。
この節では#Treap#と呼ばれるデータ構造を説明する。
これは\lemref{rbs}を利用して#SSet#インターフェースを実装する。
\footnote{#Treap#の名はこのデータ構造は二分木 \textbf{tr}ee(\secref{binarysearchtree})であると同時にヒープ h\textbf{eap}(\chapref{heaps}) でもあることによる。}

#Treap#のノードは値#x#を持つ点で#BinarySearchTree#に似ているが、それに加えて一意な数である\emph{優先度}#p#を持つ。
この#p#はランダムに割当てられる。
\javaimport{ods/Treap.Node<T>}
\cppimport{ods/Treap.TreapNode}
#Treap#のノードは、二分探索木の性質に加えて、\emph{ヒープ性}も満たす。
\begin{itemize}
\item （ヒープ性）根でない任意のノード#u#について$#u.parent.p# < #u.p#$が成り立つ。
      \index{heap property}%
\end{itemize}
言い換えると、どのノードの優先度も、そのふたつの子いずれの優先度よりも小さい。
\figref{treap}にこの例を示した。

\begin{figure}
  \begin{center}
    \includegraphics[width=\ScaleIfNeeded]{figs/treap}
  \end{center}
  \caption{整数$0,\ldots,9$を含む#Treap#の例。ノード#u#は$#u.x#,#u.p#$を含む四角形として描かれている。}
  \figlabel{treap}
\end{figure}

ヒープ性と二分探索木の性質とを共に満たすことから、キー#x#と優先度#p#が決まると#Treap#の形状は一意に定まる。
ヒープ性から最小の優先度を持つノードが#Treap#の根#r#であることがわかる。
二分探索木性から#r.x#より小さなキーを持つノードは#r.left#を根とする部分木に含まれ、#r.x#より大さなキーを持つノードは#r.right#を根とする部分木に含まれることがわかる。

#Treap#の優先度の重要な特徴は、一意であり、かつランダムに割当てられることである。
このことから#Treap#のふたつ等価な解釈の仕方がある。
先ほどに定義したように、#Treap#はヒープ性と二分探索木性を満たす。
この代わりに、#Treap#を優先度の昇順にノードが追加される#BinarySearchTree#だと考えることもできる。
例えば\figref{treap}の#Treap#は、#BinarySearchTree#に対して次の値$(#x#,#p#)$の列を追加すると得られる。
\[
  \langle
   (3,1), (1,6), (0,9), (5,11), (4,14), (9,17), (7,22), (6,42), (8,49), (2,99)
  \rangle
\]

優先度はランダムに決まるので、これはキーをランダムに置換するのと同じである。
上の例は次の置換に対応する。
\[
  \langle 3, 1, 0, 5, 9, 4, 7, 6, 8, 2 \rangle
\]
これらを#BinarySearchTree#に追加すればよい。
これは#Treap#の形状は、ランダム二分探索木と同じであることを意味する。
特にもしキー#x#をそのランクに置き換えると
\footnote{#x#を集合$S$の要素とするとき、#x#のランクとは$S$の要素のうち#x#より小さいものの個数である。}
\lemref{rbs}を適用できる。
\lemref{rbs}を#Treap#のコトバで言い換えると次のようになる。
\begin{lem}\lemlabel{rbs-treap}
  #n#個のキーからなる集合$S$を保持する#Treap#において次の命題が成り立つ。
  \begin{enumerate}
    \item 任意の$#x#\in S$について#x#の探索経路の長さの期待値は$H_{r(#x#)+1} + H_{#n#-r(#x#)} - O(1)$である。
    \item 任意の$#x#\not\in S$について#x#の探索経路の長さの期待値は$H_{r(#x#)} + H_{#n#-r(#x#)}$である。
  \end{enumerate}
  ここで$r(#x#)$は集合$S\cup\{#x#\}$における#x#のランクである。
\end{lem}
繰り返しになるが、\lemref{rbs-treap}の期待値は、頂点の優先度割当てのランダム性に基づく。これはキーがランダムであることは仮定していない。

\lemref{rbs-treap}より、#Treap#の#find(x)#を効率よく実装できることがわかる。
しかし本当に有用なのは#add(x)#・#delete(x)#操作を実装できることである。
このためにヒープ性を保つための回転操作が必要である。
\figref{rotations}を参照せよ。
二分探索木の\emph{回転}とは
\index{rotation}%
ノード#w#とその親#u#について、二分探索木性を保ちながら#w#を#u#の親にする操作である。
回転には\emph{右回転}と\emph{左回転}の二種類があって、それぞれ#w#が#u#の右の子であるか、左の子であるかに対応する。
\index{left rotation}%
\index{right rotation}%

\begin{figure}
  \begin{center}
     \includegraphics[width=\ScaleIfNeeded]{figs/rotation}
  \end{center}
  \caption{二分探索木の左回転・右回転}
  \figlabel{rotations}
\end{figure}

これを実装するときには、ふたつの場合を処理し、コーナーケース（#u#が根である場合）にも注意しなければならない。
そのため実際のコードは\figref{rotations}を見て想像するものよりも少し長い。
\codeimport{ods/BinarySearchTree.rotateLeft(u).rotateRight(u)}
\label{page:rotations}
#Treap#における回転の重要な性質は、#w#の深さが1減り、#u#の深さが1増えることだ。

回転を使って#add(x)#を次のように実装できる。
新しいノード#u#を作り、#u.x=x#とし、#u.p#を乱数で初期化する。
#u#を#BinarySearchTree#の#add(x)#アルゴリズムを使って追加する。
このとき#u#は#Treap#の葉になる。
ここで#Treap#は二分探索木性を満たすが、ヒープ性を満たすとは限らない。
特にこれは#u.parent.p > u.p#の場合である。
この場合、#w#=#u.parent#で回転操作実行し、#u#を#w#の親にする。
#u#が引き続きヒープ性を犯しているなら、これを繰り返す。
この度に#u#の深さは1減り、#u#が根になるか$#u.parent.p# < #u.p#$を満たすと処理は終了する。
\codeimport{ods/Treap.add(x).bubbleUp(u)}
\figref{treap-add}に#add(x)#操作の例を示した。

\begin{figure}
  \begin{center}
  \includegraphics[width=\ScaleIfNeeded]{figs/treap-insert-a} \\
  \includegraphics[width=\ScaleIfNeeded]{figs/treap-insert-b} \\
  \includegraphics[width=\ScaleIfNeeded]{figs/treap-insert-c} \\
  \end{center}
  \caption{\figref{treap}の#Treap#に値1.5を追加する。}
  \figlabel{treap-add}
\end{figure}

#add(x)#操作の実行時間は#x#の探索経路の長さと、新たに追加されたノード#u#を#Treap#におけるあるべき位置まで移動するための回転する回数から求まる。
\lemref{rbs-treap}より探索経路の長さの期待値は$2\ln #n#+O(1)$以下である。
さらに回転のたびに#u#の深さは減る。
#u#が根になると処理が終了するので、回転回数の期待値は探索経路長の期待値以下である。
よって、#Treap#における#add(x)#の実行時間の期待値は$O(\log #n#)$である。
（\excref{treap-rotates}はこの操作における回転の回数の期待値は実は$O(1)$であることを示す問題である。）

#Treap#における#remove(x)#は#add(x)#の逆である。
#x#を含むノード#u#を探し、#u#が葉に来るまで下方向に回転を繰り返し、最後に#u#を取り外す。
#u#を下方向に動かすとき、右に回転するか左に回転するかの選択肢があることに注意する。
この選択は次の規則に従う。
\begin{enumerate}
\item #u.left#と#u.right#がいずれも#null#なら、#u#は葉なので回転の必要はない
\item #u.left#または#u.right#が#null#なら、#null#でない方と回転で#u#を入れ替える
\item $#u.left.p# < #u.right.p#$ならば右に回転し、そうでないなら左に回転する
\end{enumerate}
この規則により#Treap#は連結であり、またヒープ性も保たれることがわかる。
\codeimport{ods/Treap.remove(x).trickleDown(u)}
\figref{treap-remove}に#remove(x)#の例を示した。
\begin{figure}
  \begin{center}
  \includegraphics[height=\QuarterHeightScaleIfNeeded]{figs/treap-delete-a} \\
  \includegraphics[height=\QuarterHeightScaleIfNeeded]{figs/treap-delete-b} \\
  \includegraphics[height=\QuarterHeightScaleIfNeeded]{figs/treap-delete-c} \\
  \includegraphics[height=\QuarterHeightScaleIfNeeded]{figs/treap-delete-d}
  \end{center}
  \caption{\figref{treap}の#Treap#から値9を削除する。}
  \figlabel{treap-remove}
\end{figure}

#remove(x)#の実行時間の解析におけるポイントは、#add(x)#の逆の操作になっていることだ。
特に#x#を同じ優先度#u.p#で再挿入することを考えると、#add(x)#操作はちょうど同じ数の回転を実行し、#Treap#は#remove(x)#の直前の状態に戻る。
（\figref{treap-remove}を下から上に見ると値9を#Treap#に追加している様子になっている。）
これは大きさ#n#の#Treap#の#remove(x)#操作の実行時間の期待値は、大きさ#n-1#の#Treap#の#add(x)#操作の実行時間の期待値に比例するということである。
すなわち、#remove(x)#の実行時間の期待値は$O(\log #n#)$である。

\subsection{要約}

次の定理は#Treap#の性能をまとめるものだ。

\begin{thm}
#Treap#は#SSet#インターフェースを実装する。
#Treap#は#add(x)#・#remove(x)#・#find(x)#をサポートし、いずれの実行時間の期待値も$O(\log #n#)$である。
\end{thm}

#Treap#と#SkiplistSSet#を比べてみるのは面白いだろう。
いずれも#SSet#の実装で、各操作の実行時間の期待値は$O(\log #n#)$である。
どちらのデータ構造でも#add(x)#・#remove(x)#は検索に続く定数回のポインタの更新からなる。
（下の\excref{treap-rotates}を見よ）
よってどちらのデータ構造でも探索経路の長さの期待値が性能を決める重要な値である。
#SkiplistSSet#では探索経路の長さの期待値は次のようである。
\[
     2\log #n# + O(1)
\]
#Treap#では次のようである。
\[
    2\ln #n# +O(1) \approx 1.386\log #n#  + O(1)
\]
よって#Treap#における探索経路の方が短く、各操作も#Skiplist#よりも#Treap#の方がかなり早いと解釈できるだろう。
\chapref{skiplists}の\excref{skiplist-opt}で示したように、偏ったコイントスを使って、#Skiplist#における探索経路の長さの期待値を次のように減らせる。
\bf{XXX: SkiplistSSetの誤植?}
\[
     e\ln #n# + O(1) \approx 1.884\log #n# + O(1)
\]
この最適化を採用しても、#SkiplistSSet#における探索経路の期待値は、やはり#Treap#のそれよりだいぶ長いのである。

\section{ディスカッションと練習問題}

ランダム二分探索木についての研究は多岐に渡る。
Devroye\cite{d88}が\lemref{rbs}とそれに関連した成果を証明した。
より強い結果も複数知られているが、もっとも印象的なのはReed\cite{r03}の成果である。
この文献ではランダム二分探索木の高さの期待値が次の式になることを示した。
\[
  \alpha\ln n - \beta\ln\ln n + O(1)
\]
ここで$\alpha\approx4.31107$は$[2,\infty)$範囲における$\alpha\ln((2e/\alpha))=1$の唯一の解であり、$\beta=\frac{3}{2\ln(\alpha/2)}$である。
さらに、高さの分散は定数である。

#Treap#という名前はSeidelとAragon\cite{as96}が考えた。
この文献では#Treap#といくつかの変種を議論している。
しかし、#Treap#の基本的なデータ構造はVuillemin\cite{v80}が先に研究しており、この文献ではCartesian treeと呼んでいた。

#Treap#における空間効率の最適化として、各ノードに明示的に優先度#p#を蓄えずに済ませる方法がある。
代わりに、#u#の優先度として#u#のメモリアドレスのハッシュ値を用いる。
多くのハッシュ関数が実用的には上手く動作するが、\lemref{rbs}の証明の正しさを保つためには、\emph{min-wise independent性}を満たす関数族からランダムに選出した関数を使う必要がある。
\index{min-wise independence}%
min-wise independent性とは次の性質である。
相異なる任意の値$x_1,\ldots,x_k$について、それぞれのハッシュ値$h(x_1),\ldots,h(x_k)$は高い確率で相異なる値を取る。
すなわち、ある定数$c$が存在して、任意の$i\in\{1,\ldots,k\}$について次の式が成り立つ。
\[
   \Pr\{h(x_i) = \min\{h(x_1),\ldots,h(x_k)\}\} \le c/k
\]
この性質を持つハッシュ関数で、実装が簡単、かつ高速なものとして
\emph{tabulation hashing}がある。（\secref{tabulation}を参照せよ。）
\index{tabulation hashing}%
\index{hashing!tabulation}%

#Treap#の他の変種であって、優先度を各ノードに蓄えないものとして、randomized binary search treeがある。
\index{randomized binary search tree}%
\index{binary search tree!randomized}%
これはMart\'\i nezとRoura \cite{mr98}が提案した。
任意のノード#u#は#u#を根とする部分木の大きさ#u.size#を保持する。
#add(x)#・#remove(x)#いずれのアルゴリズムもランダム化されている。
#x#を#u#を根とする部分木に追加するアルゴリズムは次のものである。
\begin{enumerate}
   \item 確率$1/(#size(u)#+1)$で#x#はふつうに葉として追加され、回転によって#x#は部分木の根に向けて動いてくる。
   \item そうでなければ（すなわち確率$1-1/(#size(u)#+1)$で、#x#は#u.left#または#u.right#の適切な方を根とする部分木に再帰的に追加される。
\end{enumerate}
ひとつめの場合は#Treap#における#add(x)#において#x#のノードがランダムな優先度として#size(u)#個のいずれの値よりも小さい値を取る場合に対応しており、この事象の発生確率をそのままアルゴリズムに使っている。

#x#をrandomized binary search treeから削除するやり方は#Treap#における削除と似ている。
#x#を含むノード#u#を見つけ、これが葉に到達するまで繰り返し深さを増やしながら回転し、そこで木から切り離す。
各ステップにおける回転が右か左かをランダムに決める。
\begin{enumerate}
  \item
  確率#u.left.size/(u.size-1)#で#u#において右回転を行う。
  すなわち#u.left#を部分木の根に持ってくる。
  \item
  確率#u.right.size/(u.size-1)#で#u#において左回転を行う。
  すなわち#u.right#を部分木の根に持ってくる。
\end{enumerate}
ここでも#Treap#において#u#で左右の回転を行う確率と同じであることを簡単に確認できる。

#Treap#と比べてrandomized binary search treeには短所がある。
要素の追加・削除の際にたくさんランダムな選択をする必要があり、また部分木の大きさを保持しなければならないのである。
randomized binary search treeの長所は、部分木の大きさを他の目的、例えばランクを$O(\log #n#)$の期待実行時間で計算するのにも使えることである。（\excref{treap-get}を参照せよ。）
一方、#Treap#の優先度には木のバランスを保つ以外の用途はない。

\begin{exc}
  \figref{treap}の#Treap#に4.5を優先度7で追加し、続いて値7.5を優先度20で追加する様子を図示せよ。
\end{exc}

\begin{exc}
  \figref{treap}の#Treap#から5と7を削除する様子を図示せよ。
\end{exc}

\begin{exc}
  \figref{rbs-lvc}の右の木を生成する操作の列が$21,964,800$通りあることを示せ。（ヒント：高さ$h$の完全二分木の個数に関する漸化式を作り、$h=3$の場合を評価せよ。）
\end{exc}

\begin{exc}
  #permute(a)#メソッドを設計・実装せよ。
  これは#n#個の相異なる値を含む配列#a#を入力とし、#a#のランダムな置換を返すものである。
  実行時間は$O(#n#)$であり、$#n#!$通りの置換がいずれも当確率で現れる必要がある。
\end{exc}

\begin{exc}\exclabel{treap-rotates}
\lemref{rbs-treap}を利用して、#add(x)#における回転回数の期待値が$O(1)$であることを示せ。（このことから#remove(x)#の場合も同様のことがわかる。）
\end{exc}

\begin{exc}
#Treap#の実装を明示的に優先度を保持しないように修正せよ。
その際優先度として、各ノードのハッシュ値を利用せよ。
\end{exc}

\begin{exc}
二分探索木の各ノード#u#は高さ#u.height#、#u#を根とする部分木の大きさ#u.size#を保持していると仮定する。
  \begin{enumerate}
    \item 左または右の回転を#u#で実行すると、回転によって影響を受けるすべてのノードにおけるふたつの値を定数時間で更新できることを示せ。
    \item 各ノードの深さも保持することにすると、上と同様の結果が成り立たなくなることを説明せよ。
  \end{enumerate}
\end{exc}

\begin{exc}
  #n#要素からなる整列済み配列#a#から#Treap#を構築するアルゴリズムを設計・実装せよ。
  この操作の実行時間は最悪の場合でも$O(#n#)$である必要がある。
  また#a#の要素を順に#add(x)#メソッドで追加して得られる#Treap#と同一の#Treap#が得られなければならない。
\end{exc}

\begin{exc}
  \index{finger}%
  \index{finger search!in a treap}%
  この問題では#Treap#において、与えられたポインタの近くにあるノードを効率的に見つける方法を明らかにする。
  \begin{enumerate}
    \item 各ノードが自身を根とする部分木における最大値・最小値を保持する#Treap#を設計・実装せよ。
    \item この情報を使って、#fingerFind(x,u)#を実装せよ。
	これは#u#の助けを借りて#find(x)#を実行する操作である。
	（#u#は#x#から遠くないノードであれば望ましい。）
	この操作は#u#から上に向かって進み$#w.min#\le #x#\le #w.max#$を満たすノード#w#を見つける。
	その後は#w#からふつうのやり方で#x#を検索する。
	（#fingerFind(x,u)#の実行時間は$O(1+\log r)$であることを示せる。
	ここで、$r$は#Treap#の要素であって、その値が#x#と#u.x#の間にあるものの数である。）
	\item #Treap#の実装を拡張し、#find(x)#の探索を開始するノードを、直近の#find(x)#で見つかったノードとするようにせよ。
  \end{enumerate}
\end{exc}

\begin{exc}\exclabel{treap-get}
#Treap#におけるランクが#i#であるキーを返す操作#get(i)#を設計・実装せよ。
（ヒント：各ノード#u#が#u#を根とする部分木の大きさを保持するようにするとよい。）
\end{exc}

\begin{exc}
  \index{TreapList@#TreapList#}
  #TreapList#を実装せよ。
  これは#List#インターフェースをTreapとして実装したものだ。
  各ノードはリストのアイテムを保持し、行きがけ順で辿るとリストに入っている順でアイテムが見つかる。
  #List#の操作#get(i)#・#set(i,x)#・#add(i,x)#・#remove(i)#の期待実行時間はいずれも$O(\log #n#)$である必要がある。
\end{exc}



\begin{exc}\exclabel{treap-split}
  #split(x)#をサポートする#Treap#を設計・実装せよ。
  この操作は#Treap#に含まれる#x#より大きいすべての値を削除し、削除された値をすべて含む新たな#Treap#を返すものである。

  \noindent 例：
  #t2 = t.split(x)#は#t#から#x#より大きい値をすべて削除し、削除した値をすべて含む新たな#Treap# #t2#を返す。
  #split(x)#の実行時間の期待値は$O(\log #n#)$である必要がある。

  \noindent 注意：
  この修正後も#size()#は定数時間で正しく動く必要がある。
  これは\excref{treap-get}のために必要である。
\end{exc}

\begin{exc}\exclabel{treap-join}
#split(x)#の逆であると考えられる#absorb(t2)#をサポートする#Treap#を設計・実装せよ。
この操作は#Treap# #t2#からすべての値を削除し、それらをレシーバーに追加する。
また、この操作は#t#の最小値はレシーバーの最大値よりも大きいことを前提とする。
なお、#absorb(t2)#の期待実行時間は$O(\log #n#)$である必要がある。
\end{exc}

\begin{exc}
  この節で説明したMartinezのrandomized binary search treesを実装せよ。
  また、#Treap#の実装と性能を比較せよ。
\end{exc}

