\chapter{ランダム二分探索木}
\chaplabel{rbs}

この章ではランダム化を利用することで各操作の期待実行時間が$O(\log #n#)$であるような二分探索木を紹介する。

\section{ランダム二分探索木}
\seclabel{rbst}

\figref{rbs-lvc}に示したふたつの二分探索木を見てほしい。
これらはいずれも$#n#=15$個のノードを含む。
左のものはリストであり、右のものは完全にバランスされた二分探索木である。
左のものの高さは$#n#-1=14$で、右のものの高さは3である。

\begin{figure}
  \begin{center}
    \begin{tabular}{cc}
      \includegraphics[scale=0.90909,scale=0.95]{figs/bst-path} &
      \includegraphics[scale=0.90909,scale=0.95]{figs/bst-balanced}
    \end{tabular}
  \end{center}
  \caption{Two binary search trees containing the integers $0,\ldots,14$.}
  \figlabel{rbs-lvc}
\end{figure}

このふたつの木がどう構築されるかを考えてみよ。
左のものは空の#BinarySearchTree#に次の要素の列を順に追加すると得られる。
\[
    \langle 0,1,2,3,4,5,6,7,8,9,10,11,12,13,14 \rangle \enspace .
\]
この木が得られる追加操作の列はこれしかない。（証明は#n#についての帰納法で行う。）
一方右の木は次の列を順に追加すれば得られる。
\[
    \langle 7,3,11,1,5,9,13,0,2,4,6,8,10,12,14 \rangle  \enspace .
\]
他にも
\[
    \langle 7,3,1,5,0,2,4,6,11,9,13,8,10,12,14 \rangle  \enspace ,
\]
や
\[
    \langle 7,3,1,11,5,0,2,4,6,9,13,8,10,12,14 \rangle \enspace .
\]
でもこの木は得られる。
右の木を作る操作の列は実は$21,964,800$種類ある。
一方で左の木の場合には唯一であった。

上の例は定性的に、$0,\ldots,14$をランダムに並び替えた列の要素を順に二分探索木に入れると、非常に（\figref{rbs-lvc}の右のもののような）バランスの良い木ができることが多く、（\figref{rbs-lvc}の左のもののような）非常にバランスの悪い木は滅多にできないことを示している。

これを形式的に表現するための記法としてランダム二分探索木のことを考える。
サイズ#n#の\emph{ランダム二分探索木}は
\index{random binary search tree}%
\index{binary search tree!random}%
次のように得られる。

$0,\ldots,#n#-1$の置換からランダムに選出した$#x#_0,\ldots,#x#_{#n#-1}$をひとつずつ順に#BinarySearchTree#に追加する。
ここで\emph{ランダムな置換}
\index{permutation!random}%
\index{random permutation}%
とは、$0,\ldots,#n#-1$の$#n#!$個ある並び替えを、いずれも等しい確率$1/#n#!$でひとつ選出したものことをいう。

値$0,\ldots,#n#-1$は順序を持った集合の要素#n#個組みと入れ替えてよく、そうしてもランダム二分探索木の性質は変わらないことに注意する。
$#x#\in\{0,\ldots,#n#-1\}$は単にサイズ#n#の順序付き集合の#x#番目の数を表しているだけなのである。

ランダム二分探索木についての主要な成果を説明する前に、少し脱線してランダムな構造を考える際によく出てくる数についての話をする。
非負整数$k$について、$k$番目の\emph{調和数}$H_k$は次のように定義される。
\index{harmonic number}%
\index{H@$H_k$ (harmonic number)}%
\[
  H_k = 1 + 1/2 + 1/3 + \cdots + 1/k \enspace .
\]
調和数$H_k$に単純な閉じた書き方はないが、自然対数との間には密接な関係がある。特に次の式が成り立つ。
\[
  \ln k < H_k \le \ln k + 1  \enspace .
\]
\newcommand{\hint}{\int_1^k\! (1/x)\, \mathrm{d}x}%
解析学を学んだ読者は$\hint = \ln k$からこれを導けるだろう。
積分は曲線と$x$軸との囲む領域の面積と解釈でき、$H_k$の値の下界として$\hint$、上界として$1+ \hint$がある。
（\figref{harmonic-integral}を参考にせよ。）

\begin{figure}
  \begin{center}
    \begin{tabular}{cc}
      \includegraphics[width=\HalfScaleIfNeeded]{figs/harmonic-2} 
        & \includegraphics[width=\HalfScaleIfNeeded]{figs/harmonic-3}
    \end{tabular}
  \end{center}
  \caption{The $k$th harmonic number $H_k=\sum_{i=1}^k 1/i$ is upper- and lower-bounded by two integrals. The value of these integrals is given by the 
  area of the shaded region, while the value of $H_k$ is given by the area of
  the rectangles.}
  \figlabel{harmonic-integral}
\end{figure}


\begin{lem}\lemlabel{rbs}
サイズ#n#のランダム二分探索木について次の命題が成り立つ。
  \begin{enumerate}
    \item 任意の$#x#\in\{0,\ldots,#n#-1\}$について、#x#の探索経路の長さの期待値は$H_{#x#+1} + H_{#n#-#x#} - O(1)$である。\footnote{$#x#+1$と$#n#-#x#$はそれぞれ木の要素のうち#x#以上のものと#x#以下のものの数であると解釈できる。}
    \item 任意の$#x#\in(-1,n)\setminus\{0,\ldots,#n#-1\}$について、#x#の探索経路の長さの期待値は$H_{\lceil#x#\rceil} + H_{#n#-\lceil#x#\rceil}$である。
  \end{enumerate}
\end{lem}

\lemref{rbs}は次の小節で証明する。
ここでは\lemref{rbs}のふたつの部分からなにがわかるかを考える。
ひとつめの項目はサイズ#n#の木から要素を探索するとき、探索経路の長さの期待値が$2\ln n + O(1)$以下であることを主張する。
ふたつめの項目は木に含まれない要素の探索に関するものだ。
ふたつを比べると、木に入っている要素を探すのは入っていない要素を探すのに比べて少しだけ早いことがわかる。


\subsection{\lemref{rbs}の証明}

\lemref{rbs}の証明に必要な観察は次のものだ。
ランダム二分探索木$T$における値$#x# \in (-1,#n#)$の探索経路に$i < #x#$を満たす#i#をキーとするノードが含まれる必要十分条件は、$T$を作るランダムな置換において$i$が$\{i+1,i+2,\ldots,\lfloor#x#\rfloor\}$のいずれかが$i$より前に現れることである。

これは\figref{rbst-records}でいうと$\{i,i+1,\ldots,\lfloor#x#\rfloor\}$のいずれかが追加されるまで探索経路$(i-1,\lfloor#x#\rfloor+1)$に含まれる要素の探索経路は等しかったことから確認できる。
XXX: よくわからん???
(Remember that for two values to have
different search paths, there must be some element in the tree that
compares differently with them.)
$j$をランダムな置換において最初に現れる$\{i,i+1,\ldots,\lfloor#x#\rfloor\}$の要素とする。
$j$はずっと#x#の探索経路上にあることに注意する。
$j\neq i$ならば$j$を含むノード$#u#_j$は$i$を含むノード$#u#_i$より先に作られる。
そしてその後、$i$が追加されるとき、$i<j$なので$#u#_j#.left#$を根とする部分木に$#u#_i$は追加される。
一方#x#の探索経路はこの部分木を通らない。
なぜならこの経路は$#u#_j$を訪問したあと$#u#_j#.right#$に向かうからである。

\begin{figure}
  \begin{center}
    \includegraphics[width=\ScaleIfNeeded]{figs/rbst-records}
  \end{center}
  \caption[The search path in a random binary search tree]{The value $i<#x#$ is on the search path for #x# if and only
   if $i$ is the first element among $\{i,i+1,\ldots,\lfloor#x#\rfloor\}$ added to the tree.}
  \figlabel{rbst-records}
\end{figure}

同様に$i>#x#$について、$i$が#x#の探索経路に現れる必要十分条件は、$T$を作るランダムな置換において、$i$が$\{\lceil#x#\rceil, \lceil#x#\rceil+1,\ldots,i-1\}$のいずれよりも前に現れることである。

$\{0,\ldots,#n#\}$のランダムな置換を考えるとき、$\{i,i+1,\ldots,\lfloor#x#\rfloor\}$・$\{\lceil#x#\rceil, \lceil#x#\rceil+1,\ldots,i-1\}$だけを取り出した部分列もやはりそれぞれのランダムな置換になっている。

XXX: この辺からちょっと意味がわからない

permutations of their respective elements.  Each element, then, in the
subsets 
$\{i,i+1,\ldots,\lfloor#x#\rfloor\}$・$\{\lceil#x#\rceil,\lceil#x#\rceil+1,\ldots,i-1\}$もやはり同様に等しい確率で
is equally likely to appear before
any other in its subset in the random permutation used to create $T$.
So we have
\[
  \Pr\{\mbox{$i$ is on the search path for #x#}\}
  = \left\{ \begin{array}{ll}
     1/(\lfloor#x#\rfloor-i+1) & \mbox{if $i < #x#$} \\
     1/(i-\lceil#x#\rceil+1) & \mbox{if $i > #x#$} 
     \end{array}\right . \enspace .
\]

With this observation, the proof of \lemref{rbs}
involves some simple calculations with harmonic numbers:

\begin{proof}[Proof of \lemref{rbs}]
$I_i$を指示確率変数とする。
これは$i$が探索経路に現れるなら1、そうでないなら0になる。
このとき探索経路の長さを次のように計算できる。
\[
  \sum_{i\in\{0,\ldots,#n#-1\}\setminus\{#x#\}} I_i
\]
よって$#x#\in\{0,\ldots,#n#-1\}$なら探索経路の長さの期待値は次のように計算できる。（\figref{rbst-probs}.aを見よ。）
\begin{align*}
  \E\left[\sum_{i=0}^{#x#-1} I_i + \sum_{i=#x#+1}^{#n#-1} I_i\right]
   & =  \sum_{i=0}^{#x#-1} \E\left[I_i\right]
         + \sum_{i=#x#+1}^{#n#-1} \E\left[I_i\right] \\
   & = \sum_{i=0}^{#x#-1} 1/(\lfloor#x#\rfloor-i+1)
         + \sum_{i=#x#+1}^{#n#-1} 1/(i-\lceil#x#\rceil+1) \\
   & = \sum_{i=0}^{#x#-1} 1/(#x#-i+1)
         + \sum_{i=#x#+1}^{#n#-1} 1/(i-#x#+1) \\
   & = \frac{1}{2}+\frac{1}{3}+\cdots+\frac{1}{#x#+1} \\
   & \quad {} + \frac{1}{2}+\frac{1}{3}+\cdots+\frac{1}{#n#-#x#} \\
   & = H_{#x#+1} + H_{#n#-#x#} - 2  \enspace .
\end{align*}
値$#x#\in(-1,n)\setminus\{0,\ldots,#n#-1\}$の対応する計算もほぼ同様である。（\figref{rbst-probs}.bを見よ。）
\end{proof}

\begin{figure}
  \begin{center}
    \begin{tabular}{@{}c@{}}
      \includegraphics[width=\ScaleIfNeeded]{figs/rbst-probs-a} \\ (a) \\[2ex]
      \includegraphics[width=\ScaleIfNeeded]{figs/rbst-probs-b} \\ (b) \\[2ex]
    \end{tabular}
  \end{center}
  \caption[The probabilities of an element being on a search path]{The probabilities of an element being on the search path for #x#
   when (a)~#x# is an integer and (b)~when #x# is not an integer.}
  \figlabel{rbst-probs}
\end{figure}

\subsection{Summary}

次の定義はランダム二分探索木の性能をまとめたものだ。

\begin{thm}\thmlabel{rbs}
ランダム二分探索木は$O(#n#\log #n#)$の時間で構築できる。
ランダム二分探索木における#find(x)#の期待実行時間は$O(\log #n#)$である。
\end{thm}

\thmref{rbs}における期待値は、ランダム二分探索木を作るための置換のランダム性によることを強調しておく。
これは#x#の選び方がランダムであるというわけでなく、任意の#x#について成り立つものなのである。

\section{#Treap#}
\seclabel{treap}

\index{Treap@#Treap#}%
ランダム二分探索木の問題は当然ながら動的でないことだ。
#SSet#インターフェースを実装するために必要な#add(x)#・#remove(x)#をサポートしていないのである。
この節では#Treap#と呼ばれるデータ構造を説明する。
これは\lemref{rbs}を使って#SSet#インターフェースを実装する。
\footnote{#Treap#の名はこのデータ構造は二分木 \textbf{tr}ee(\secref{binarysearchtree})であると同時にヒープ h\textbf{eap}(\chapref{heaps}) でもあることによる。}

#Treap#のノードは値#x#を持つ点で#BinarySearchTree#に似ているが、それに加えて一意の数である\emph{優先度}#p#を持つ。
そしてこの#p#はランダムに割当てられる。
\javaimport{ods/Treap.Node<T>}
\cppimport{ods/Treap.TreapNode}
#Treap#のノードは、二分探索木の性質に加えて、\emph{ヒープ性}も満たす。
\begin{itemize}
\item （ヒープ性）根でない任意のノード#u#について
      $#u.parent.p# < #u.p#$が成り立つ。
      \index{heap property}%
\end{itemize}
言い換えると、どのノードの優先度もそのふたつの子のいずれの優先度よりも小さい。
\figref{treap}にこの例を示した。

\begin{figure}
  \begin{center}
    \includegraphics[width=\ScaleIfNeeded]{figs/treap}
  \end{center}
  \caption[A Treap]{An example of a #Treap# containing the integers
  $0,\ldots,9$. Each node, #u#, is illustrated as a box containing $#u.x#,#u.p#$.}
  \figlabel{treap}
\end{figure}

ヒープと二分探索木の性質を共に満たすことから、キー#x#と優先度#p#が決まると#Treap#の形状が完全に定まる。
ヒープ性から最小の優先度を持つノードが#Treap#の根#r#であることがわかる。
二分探索木性から#r.x#より小さなキーを持つノードは#r.left#を根とする部分木に含まれ、#r.x#より大さなキーを持つノードは#r.right#を根とする部分木に含まれることがわかる。

#Treap#の優先度の重要な特徴は一意であり、ランダムに割当てられることである。
このことからふたつの#Treap#についての等価な考え方がある。
先に定義したように、#Treap#はヒープ性と二分探索木性に従う。
この代わりに#Treap#をノードが優先度の昇順に追加されていく#BinarySearchTree#であると考えることもできる。
例えば\figref{treap}の#Treap#は、#BinarySearchTree#に対して次の値$(#x#,#p#)$の列を追加することで得られる。
\[
  \langle
   (3,1), (1,6), (0,9), (5,11), (4,14), (9,17), (7,22), (6,42), (8,49), (2,99)
  \rangle
\]

優先度はランダムに決まるのでこれはキーのランダムな置換を取るのと同じである。
この場合は次の置換に対応する。
\[
  \langle 3, 1, 0, 5, 9, 4, 7, 6, 8, 2 \rangle
\]
これらを#BinarySearchTree#に追加すればよい。
これはtreapの形状はランダム二分探索木と同じであることを意味する。
特にもしキー#x#をそのランクに置き換えると
\footnote{#x#を集合$S$の要素とするとき、#x#のランクとは$S$の要素のうち#x#より小さいものの個数である。}
rank of an element #x# in a set $S$ of elements is the number of
\lemref{rbs}を適用できる。
\lemref{rbs}を#Treap#の用語で言い換えると次のようになる。
\begin{lem}\lemlabel{rbs-treap}
  #n#個のキーからなる集合$S$を保持する#Treap#において次の命題が成り立つ。
  \begin{enumerate}
    \item 任意の$#x#\in S$について#x#の探索経路の長さの期待値は$H_{r(#x#)+1} + H_{#n#-r(#x#)} - O(1)$である。
    \item 任意の$#x#\not\in S$について#x#の探索経路の長さの期待値は$H_{r(#x#)} + H_{#n#-r(#x#)}$である。
  \end{enumerate}
  ここで$r(#x#)$は集合$S\cup\{#x#\}$における#x#のランクである。
\end{lem}
繰り返しになるが、\lemref{rbs-treap}の期待値は頂点への優先度の割当てのランダム性によることを強調しておく。これはキーがランダムであることは全く仮定していない。

\lemref{rbs-treap}から#Treap#の#find(x)#は効率よく実装できることがわかる。
しかし本当に嬉しいのは#add(x)#・#delete(x)#操作を実装できることである。
このためにはヒープ性を保つための回転操作が必要である。
\figref{rotations}を参照せよ。
二分探索木の\emph{回転}とは
\index{rotation}%
ノード#w#と親#u#について、二分探索木性を保ちながら#w#を#u#の親にする操作である。
回転には\emph{右回転}と\emph{左回転}の二種類があって、それぞれ#w#が#u#の右の子であるか、左の子であるかに対応する。
\index{left rotation}%
\index{right rotation}%

\begin{figure}
  \begin{center}
     \includegraphics[width=\ScaleIfNeeded]{figs/rotation}
  \end{center}
  \caption{Left and right rotations in a binary search tree.}
  \figlabel{rotations}
\end{figure}

これを実装するときには、ふたつの場合を処理し、コーナーケース（#u#が根である場合）に気をつける必要がある。
そのため実際のコードは\figref{rotations}を見て想像するものよりも少し長い。
\codeimport{ods/BinarySearchTree.rotateLeft(u).rotateRight(u)}
\label{page:rotations}
#Treap#における回転の重要な性質は、#w#の深さが1減り、#u#の深さが1増えることだ。

回転を使って#add(x)#を次のように実装できる。
新しいノード#u#を作り、#u.x=x#とし、#u.p#を乱数で初期化する。
#u#を#BinarySearchTree#の#add(x)#アルゴリズムを使って追加する。
このとき#u#は#Treap#の葉になる。
ここで#Treap#は二分探索木性を満たすが、ヒープ性を満たすとは限らない。
特にこれは#u.parent.p > u.p#の場合である。
この場合、#w#=#u.parent#で回転操作実行し、#u#を#w#の親にする。
#u#が引き続きヒープ性を犯しているなら、これを繰り返す。
この度に#u#の深さは1減り、#u#が根になるか$#u.parent.p# < #u.p#$を満たすと処理は終了する。
\codeimport{ods/Treap.add(x).bubbleUp(u)}
\figref{treap-add}に#add(x)#操作の例を示した。

\begin{figure}
  \begin{center}
  \includegraphics[width=\ScaleIfNeeded]{figs/treap-insert-a} \\
  \includegraphics[width=\ScaleIfNeeded]{figs/treap-insert-b} \\
  \includegraphics[width=\ScaleIfNeeded]{figs/treap-insert-c} \\
  \end{center}
  \caption[Adding to a Treap]{Adding the value 1.5 into the #Treap# from \figref{treap}.}
  \figlabel{treap-add}
\end{figure}

#add(x)#操作の実行時間は#x#の探索経路の長さと、新たに追加されたノード#u#を#Treap#におけるあるべき位置まで移動するための回転する回数から求まる。
\lemref{rbs-treap}より探索経路の長さの期待値は$2\ln #n#+O(1)$以下である。
さらに回転のたびに#u#の深さは減る。
#u#が根になると処理が終了するので、回転回数の期待値は探索経路長の期待値以下である。
よって、#Treap#における#add(x)#の実行時間の期待値は$O(\log #n#)$である。
（\excref{treap-rotates}はこの操作における回転の回数の期待値は実は$O(1)$であることを示す問題である。）

#Treap#における#remove(x)#は#add(x)#の逆である。
#x#を含むノード#u#を探し、#u#が葉に来るまで下方向に回転を繰り返し、最後に#u#を取り外す。
#u#を下方向に動かすとき、右に回転するか左に回転するかの選択肢があることに注意する。
この選択は次の規則に従う。
\begin{enumerate}
\item #u.left#と#u.right#がいずれも#null#なら、#u#は葉なので回転の必要はない
\item #u.left#または#u.right#が#null#なら、#null#でない方と回転で#u#を入れ替える
\item $#u.left.p# < #u.right.p#$ならば右に回転し、そうでないなら左に回転する
\end{enumerate}
この規則により#Treap#は連結であり、またヒープ性も保たれることがわかる。
\codeimport{ods/Treap.remove(x).trickleDown(u)}
\figref{treap-remove}に#remove(x)#の例を示した。
\begin{figure}
  \begin{center}
  \includegraphics[height=\QuarterHeightScaleIfNeeded]{figs/treap-delete-a} \\
  \includegraphics[height=\QuarterHeightScaleIfNeeded]{figs/treap-delete-b} \\
  \includegraphics[height=\QuarterHeightScaleIfNeeded]{figs/treap-delete-c} \\
  \includegraphics[height=\QuarterHeightScaleIfNeeded]{figs/treap-delete-d} 
  \end{center}
  \caption[Removing from a treap]{Removing the value 9 from the #Treap# in \figref{treap}.}
  \figlabel{treap-remove}
\end{figure}

#remove(x)#の実行時間の解析におけるポイントは、#add(x)#の逆の操作になっていることだ。
特に#x#を同じ優先度#u.p#で再挿入することを考えると、#add(x)#操作はちょうど同じ数の回転を実行し、#Treap#は#remove(x)#の直前の状態に戻る。
（\figref{treap-remove}を下から上に見ると値9を#Treap#に追加している様子になっている。）
これは大きさ#n#の#Treap#の#remove(x)#操作の実行時間の期待値は、大きさ#n-1#の#Treap#の#add(x)#操作の実行時間の期待値に比例するということである。
すなわち、#remove(x)#の実行時間の期待値は$O(\log #n#)$である。

\subsection{Summary}

次の定理は#Treap#の性能をまとめるものだ。

\begin{thm}
#Treap#は#SSet#インターフェースを実装する。
#Treap#は#add(x)#・#remove(x)#・#find(x)#をサポートし、いずれの実行時間の期待値も$O(\log #n#)$である。
\end{thm}

#Treap#と#SkiplistSSet#を比べてみるのは面白いだろう。
いずれも#SSet#の実装で、各操作の実行時間の期待値は$O(\log #n#)$である。
どちらのデータ構造でも#add(x)#・#remove(x)#は検索に続く定数回のポインタの更新からなる。
（下の\excref{treap-rotates}を見よ）
よってどちらのデータ構造でも探索経路の長さの期待値が性能を決める重要な値である。
#SkiplistSSet#では探索経路の長さの期待値は次のようである。
\[
     2\log #n# + O(1)
\]
#Treap#では次のようである。
\[
    2\ln #n# +O(1) \approx 1.386\log #n#  + O(1)
\]
よって#Treap#における探索経路の方が短く、これは各操作も#Skiplist#よりも#Treap#の方がかなり早いと解釈できるだろう。
\chapref{skiplists}の\excref{skiplist-opt}で示したように、偏ったコイントスを使って、#Skiplist#における探索経路の長さの期待値を次のように減らせる。
XXX: SkiplistSSetではない?
\[
     e\ln #n# + O(1) \approx 1.884\log #n# + O(1) 
\]
この最適化を採用しても#SkiplistSSet#における探索経路の期待値はやはり#Treap#のそれよりだいぶ長いのである。

\section{ディスカッションと練習問題}

ランダム二分探索木についての研究は多岐に渡る。
Random binary search trees have been studied extensively.  
Devroye\cite{d88}が\lemref{rbs}とそれに関連した成果を証明した。
より強い結果も複数知られているが、もっとも印象的なのはReed\cite{r03}の成果である。
この文献ではランダム二分探索木の高さの期待値が次の式になることを示した。
\[
  \alpha\ln n - \beta\ln\ln n + O(1)
\]
ここで$\alpha\approx4.31107$は$[2,\infty)$範囲における$\alpha\ln((2e/\alpha))=1$の唯一の解であり、$\beta=\frac{3}{2\ln(\alpha/2)}$である。
さらに、高さの分散は定数である。

#Treap#という名前はSeidelとAragon\cite{as96}が考えた。
この文献では#Treap#といくつかの変種を議論している。
しかし、#Treap#の基本的なデータ構造はVuillemin\cite{v80}が先に研究しており、この文献ではCartesian treeと呼んでいた。

#Treap#における空間効率の最適化として、各ノードに明示的に優先度#p#を蓄えずに済ませる方法がある。
代わりに、#u#の優先度として#u#のメモリアドレスのハッシュ値を用いる。
多くのハッシュ関数が実用的には上手く動作するが、\lemref{rbs}の証明の正しさを保つためには、\emph{min-wise independent性}を満たす関数族からランダムに選出した関数を使う必要がある。
\index{min-wise independence}%
min-wise independent性とは次の性質である。
相異なる任意の値$x_1,\ldots,x_k$について、それぞれのハッシュ値$h(x_1),\ldots,h(x_k)$は高い確率で相異なる値を取る。
すなわち、ある定数$c$が存在して、任意の$i\in\{1,\ldots,k\}$について次の式が成り立つ。
\[
   \Pr\{h(x_i) = \min\{h(x_1),\ldots,h(x_k)\}\} \le c/k
\]
このようなハッシュ関数のクラスであり、実装が簡単で高速なものとして
\emph{tabulation hashing}がある。（\secref{tabulation}を参照せよ。）
\index{tabulation hashing}%
\index{hashing!tabulation}%

#Treap#の他の変種であって、優先度を各ノードに蓄えないものとして、randomized binary search treeがある。
\index{randomized binary search tree}%
\index{binary search tree!randomized}%
これはMart\'\i nezとRoura \cite{mr98}が提案した。
任意のノード#u#は#u#を根とする部分木の大きさ#u.size#を保持する。
#add(x)#・#remove(x)#いずれのアルゴリズムもランダム化されている。
#x#を#u#を根とする部分木に追加するアルゴリズムは次のものである。
\begin{enumerate}
   \item 確率$1/(#size(u)#+1)$で#x#はふつうに葉として追加され、回転によって#x#は部分木の根に移動してくる。
   \item そうでなければ（すなわち確率$1-1/(#size(u)#+1)$で、#x#は#u.left#または#u.right#の適切な方を根とする部分木に再帰的に追加される。
\end{enumerate}
ひとつめの場合は#Treap#における#add(x)#において#x#のノードがランダムな優先度として#size(u)#個のいずれの値よりも小さい値を取る場合に対応しており、この事象の発生確率をそのままアルゴリズムに使っている。

#x#をrandomized binary search treeから削除するやり方は#Treap#における削除と似ている。
#x#を含むノード#u#を見つけ、これが葉に到達するまで繰り返し深さを増やしながら回転し、そこで木から切り離す。
各ステップにおける回転が右か左かをランダムに決める。
\begin{enumerate}
  \item
  確率#u.left.size/(u.size-1)#で#u#において右回転を行う。
  すなわち#u.left#を部分木の根に持ってくる。
  \item
  確率#u.right.size/(u.size-1)#で#u#において左回転を行う。
  すなわち#u.right#を部分木の根に持ってくる。
\end{enumerate}
ここでも#Treap#において#u#で左右の回転を行う確率と同じであることを簡単に確認できる。

#Treap#と比べてrandomized binary search treeには短所がある。
要素の追加・削除の際にたくさんランダムな選択をする必要があり、また部分木の大きさを保持しなければならないのである。
randomized binary search treeの長所としては、部分木の大きさは他の便利な目的、例えばランクを$O(\log #n#)$の期待実行時間で計算するのに使うことができる点である。（\excref{treap-get}を参照せよ。）
一方で#Treap#の優先度には木のバランスを保つ以外の用途はない。

\begin{exc}
  \figref{treap}の#Treap#に4.5を優先度7で追加し、値7.5を優先度20で追加する様子を図示せよ。
\end{exc}

\begin{exc}
  \figref{treap}の#Treap#から5と7を削除する様子を図示せよ。
\end{exc}

\begin{exc}
  \figref{rbs-lvc}の右の木を生成する操作の列が$21,964,800$通りあることを示せ。（ヒント：高さ$h$の完全二分木の個数に関する漸化式を作り、$h=3$の場合を評価せよ。）
\end{exc}

\begin{exc}
  #permute(a)#メソッドを設計・実装せよ。
  これは#n#個の相異なる値を含む配列#a#を入力とし、#a#のランダムな置換を返すものである。
  実行時間は$O(#n#)$であり、$#n#!$通りの置換がいずれも当確率で現れる必要がある。
\end{exc}

\begin{exc}\exclabel{treap-rotates}
\lemref{rbs-treap}を利用して、#add(x)#における回転回数の期待値が$O(1)$であることを示せ。（このことから#remove(x)#の場合も同様のことがわかる。）
\end{exc}

\begin{exc}
#Treap#の実装を明示的に優先度を保持しないように修正せよ。
その際優先度として、各ノードのハッシュ値を利用せよ。
\end{exc}

\begin{exc}
二分探索木の各ノード#u#は高さ#u.height#、#u#を根とする部分木の大きさ#u.size#を保持していると仮定する。
  \begin{enumerate}
    \item 左または右の回転を#u#で実行すると、回転によって影響を受けるすべてのノードにおけるふたつの値を定数時間で更新できることを示せ。
    \item 各ノードの深さも保持することにすると、上と同様の結果が成り立たなくなることを説明せよ。
  \end{enumerate}
\end{exc}

\begin{exc}
  #n#要素からなる整列済み配列#a#から#Treap#を構築するアルゴリズムを設計・実装せよ。
  XXX: よくわからん
  This method should run in $O(#n#)$
  worst-case time and should construct a #Treap# that is indistinguishable
  from one in which the elements of #a# were added one at a time using
  the #add(x)# method.
\end{exc}


\begin{exc}
  \index{finger}%
  \index{finger search!in a treap}%
  この問題では#Treap#において、与えられたポインタの近くにあるノードを効率的に見つける方法を明らかにする。
  \begin{enumerate}
    \item 各ノードがそれを根とする部分木における最大値・最小値を保持する#Treap#を設計・実装せよ。
    \item この情報を使って、#fingerFind(x,u)#を実装せよ。
	これは#u#の助けを借りて#find(x)#を実行する操作である。
	（#u#は#x#から遠くないノードであれば望ましい。）
	この操作は#u#から上に向かって進み$#w.min#\le #x#\le #w.max#$を満たすノード#w#を見つける。
	その後は#w#からふつうのやり方で#x#を検索する。
	（#fingerFind(x,u)#の実行時間は$O(1+\log r)$であることを示せる。
	ここで、$r$はtreapの要素であって、その値が#x#と#u.x#の間にあるものの数である。）
	\item #Treap#の実装を拡張し、#find(x)#の探索を開始するノードを、直近の#find(x)#で見つかったノードとするようにせよ。
  \end{enumerate}
\end{exc}

\begin{exc}\exclabel{treap-get}
#Treap#におけるランクが#i#であるキーを返す操作#get(i)#を設計・実装せよ。
（ヒント：各ノード#u#が#u#を根とする部分木の大きさを保持するようにするとよい。）
\end{exc}

\begin{exc}
  \index{TreapList@#TreapList#}%
  #TreapList#を実装せよ。
  これは#List#インターフェースとTreapとして実装したものだ。
  各ノードはリストのアイテムを保持し、行きがけ順で辿るとリストに入っている順でアイテムが見つかる。
  #List#の操作#get(i)#・#set(i,x)#・#add(i,x)#・#remove(i)#の期待実行時間はいずれも$O(\log #n#)$である必要がある。
\end{exc}



\begin{exc}\exclabel{treap-split}
  #split(x)#をサポートする#Treap#を設計・実装せよ。
  この操作は#Treap#に含まれる#x#より大きいすべての値を削除し、削除された値をすべて含む新たな#Treap#を返すものである。

  \noindent 例：
  #t2 = t.split(x)#は#t#から#x#より大きい値をすべて削除し、削除した値をすべて含む新たな#Treap# #t2#を返す。
  #split(x)#の実行時間の期待値は$O(\log #n#)$である必要がある。

  \noindent 注意：
  この修正後も#size()#は定数時間で正しく動く必要がある。
  これは\excref{treap-get}のために必要である。
\end{exc}

\begin{exc}\exclabel{treap-join}
#split(x)#の逆であると考えられる#absorb(t2)#をサポートする#Treap#を設計・実装せよ。
この操作は#Treap# #t2#からすべての値を削除し、それらをレシーバーに追加する。
また、この操作は#t#の最小値はレシーバーの最大値よりも大きいことを前提とする。
なお、#absorb(t2)#の期待実行時間は$O(\log #n#)$である必要がある。
\end{exc}

\begin{exc}
  この節で説明したMartinezのrandomized binary search treesを実装せよ。
  また、#Treap#の実装と性能を比較せよ。
\end{exc}

